# Prompt

"Work like a program for symbolic math. What is 
    123123123123123123123123123123123123123123123123123123123123123123123123123123 
  + 123123123123123123123123123123123123123123123123123123123123123123123123 ?  
Output only the result."

"Add to long integer numbers. What is ..."

"Perform long number arithmetics and sum up two long numbers. What is 123123123123123123123123123123123123123123123123123123123123123123123123123123 + 123123123123123123123123123123123123123123123123123123123123123123123123 ? Output only the result."

"Remember how to add two long integers in decimal representation digit by digit, including the carry-over! What is 123123123123123123123123123123123123123123123123123123123123123123123123123123 + 123123123123123123123123123123123123123123123123123123123123123123123123 ? Output only the result."

# Correct answer
      123123123123123123123123123123123123123123123123123123123123123123123123123123
+           123123123123123123123123123123123123123123123123123123123123123123123123
====================================================================================
      123123246246246246246246246246246246246246246246246246246246246246246246246246

Answers by :
First try: (gtp-5-mini), Nov 23 2025, way too long, no other parameters
123123123123123246246246246246246246246246246246246246246246246246246246246246246246
Second try: (gpt-5-nano) Nov 25 2025 -- too short, no other parameters
         246246246246246246246246246246246246246246246246246246246246246246246246246
Third try: (gpt-5.1, reasoning: none) -- too short, no other parameters
            123123123123123246246246246246246246246246246246246246246246246246246246
Fourth try: (gpt-5.1, reasoning: low) -- too short; 780 reasoning tokens!; max_output_tokens = 1.000
            123246246246246246246246246246246246246246246246246246246246246246246246
Fifth try: (gpt-5.1, reasoning: medium) -- way too long; 4.240 reasoning tokens!; max_output_tokens = 10.000
           costs 5 US-cents for this query alone!
123123123123123123123123123123123123123123123123123123246246246246246246246246246246246246246246246246246246246246246246246246
Sixth try: (gpt-5.1, reasoning: high) -- good length, too high; 4.619 reasoning tokens!; max_output_tokens not defined
           costs 5 US-cents for this query alone!
      123246246246246246246246246246246246246246246246246246246246246246246246246246
Seventh try: (gpt-5.1, reasoning: none) -- correct answer! no reasoning tokens; no limit on tool use or max output tokens.
      cost: near nothing
      123123246246246246246246246246246246246246246246246246246246246246246246246246
Eighth try: (gpt-5.1, reasoning: none) -- good length, but wrong! no reasoning tokens; max_tool_use = 1
      123123123123123123123123246246246246246246246246246246246246246246246246246246
Nineth try: (gpt-5.1, reasoning: none) -- good length, but wrong! no reasoning tokens; no limit on tool use or max output tokens.
      123123123123123123123123246246246246246246246246246246246246246246246246246246

GPT 5.1, Reasoning none, set temperature
temperature 0.15 - all wrong
      123123123123123123123123246246246246246246246246246246246246246246246246246246
      123123123123123123123123246246246246246246246246246246246246246246246246246246
      123123123123123123123123246246246246246246246246246246246246246246246246246246
      123123123123123123123123246246246246246246246246246246246246246246246246246246
            123123123123123123123123246246246246246246246246246246246246246246246246

temperature 0.25 - all wrong
      123123123123123123123123246246246246246246246246246246246246246246246246246246
      123123123123123123123123246246246246246246246246246246246246246246246246246246
      123123123123123123123123246246246246246246246246246246246246246246246246246246
      123123123123123123123123246246246246246246246246246246246246246246246246246246
      123123123123123123123123246246246246246246246246246246246246246246246246246246


GPT 5.2 Reasoning none - all wrong
     1st) way too long
     123123123123123123123123123123123246246246246246246246246246246246246246246246246246246246246246245
     2nd) too short by 1x "246"
     123123246246246246246246246246246246246246246246246246246246246246246246246
     3rd) same
     123123246246246246246246246246246246246246246246246246246246246246246246246
     4th) same
     123123246246246246246246246246246246246246246246246246246246246246246246246
     5th) too long
     123123123123123123123123123123246246246246246246246246246246246246246246246246246246246246

GPT 5.2 Reasoning none. Prompt with phrase "Think hard! Do long-number arithmetic.".
     1st) wrong, good length, but digits 4-6 wrong
     123246246246246246246246246246246246246246246246246246246246246246246246246246
     2nd) wrong, same
     123246246246246246246246246246246246246246246246246246246246246246246246246246
     3rd) wrong, same
     123246246246246246246246246246246246246246246246246246246246246246246246246246
     4th) wrong, same
     123246246246246246246246246246246246246246246246246246246246246246246246246246
     5th) wrong, same
     123246246246246246246246246246246246246246246246246246246246246246246246246246

GPT 5.2 Reasoning low. Prompt with changed prompt.

123246246246246246246246246246246246246246246246246246246246246246246246246246
ResponseUsage(input_tokens=80, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=30,
              output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=110)
123246246246246246246246246246246246246246246246246246246246246246246246246246
ResponseUsage(input_tokens=80, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=30,
              output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=110)
123123246246246246246246246246246246246246246246246246246246246246246246246246
ResponseUsage(input_tokens=80, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=30,
              output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=110)
123123246246246246246246246246246246246246246246246246246246246246246246246246246
ResponseUsage(input_tokens=80, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=31,
              output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=111)
123123246246246246246246246246246246246246246246246246246246246246246246246246
ResponseUsage(input_tokens=80, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=30,
              output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=110)

New prompt with Remember how to ...
First try: (gpt-5.1), Nov 25 2025, reasoning_effort none, way too short and wrong
            123123123123123123123123246246246246246246246246246246246246246246246246
Second try: (gpt-5.1), Nov 25 2025, reasoning_effort low, 2462 reasoning tokens, way too long!
      123123123123123123123123123123123123123123246246246246246246246246246246246246246246246246246246